{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCBv4IGJZtea"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing the Datasets"
      ],
      "metadata": {
        "id": "C0bkshsLPLVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fLzTy1EdVXm"
      },
      "outputs": [],
      "source": [
        "pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUS9EI7LdVaY"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"roneneldan/TinyStories\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Tokenization of the Dataset\n"
      ],
      "metadata": {
        "id": "5Fw602NpO-Nv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aEsIVK4dVdT"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "def process(example):\n",
        "  ids = enc.encode_ordinary(example['text'])\n",
        "  out = {'ids': ids, 'len': len(ids)}\n",
        "  return out\n",
        "\n",
        "if not os.path.exists(\"train.bin\"):\n",
        "    tokenized = ds.map(\n",
        "        process,\n",
        "        remove_columns=['text'],\n",
        "        desc=\"tokenizing the splits\",\n",
        "        num_proc=8,\n",
        "        )\n",
        "\n",
        "for split, dset in tokenized.items(): # Iterating through the Dataset Splits\n",
        "        arr_len = np.sum(dset['len'], dtype=np.uint64) # Counting the number of tokens in the dset after spliting\n",
        "        filename = f'{split}.bin' # Creating two bins i.e bag of words train.bin and val.bin\n",
        "        dtype = np.uint16 # (can do since enc.max_token_value == 50256 is < 2**16) we have max tokens as 50257 as int16 can 65k so it better\n",
        "        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,)) # here mode w+ is to create a bin if not created and write the token ids into thr bin if the bin is already created\n",
        "        # IT deletes and creates a new bin\n",
        "        total_batches = 1024 # Divided into the batches\n",
        "\n",
        "        idx = 0 # Assinging the idx to batches\n",
        "        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'): # Iterating along the batches in the specified bins\n",
        "            # Batch together samples for faster write\n",
        "            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy') # It creates in any contigous 1D array manner\n",
        "            arr_batch = np.concatenate(batch['ids']) #After Shards it concats the ids\n",
        "            # Write into mmap\n",
        "            arr[idx : idx + len(arr_batch)] = arr_batch # It is Copying the token ids into the arr.memmap asn arr was empty and arr_batc contained the token ids\n",
        "            idx += len(arr_batch) # It is incrementing each one\n",
        "        arr.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEwfe_ObdVf-"
      },
      "outputs": [],
      "source": [
        "# Some functions from https://github.com/karpathy/nanoGPT/blob/master/train.py with slight modifications\n",
        "#block size = context window\n",
        "def get_batch(split):\n",
        "    # We recreate np.memmap every batch to avoid a memory leak, as per\n",
        "    # https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122\n",
        "    if split == 'train':\n",
        "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
        "    else:\n",
        "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    if device_type == 'cuda':\n",
        "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dj1bVXIsPIlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pty5AWwPdVjO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku3i-vezdVl6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SncJ1veJdVos"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efdwHg6vdVrg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}